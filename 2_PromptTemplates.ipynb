{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An ideal prompting should follow the following format\n",
    "# Instructions\n",
    "# Contenxt\n",
    "# Question\n",
    "# Output\n",
    "\n",
    "# Lets trye a prompt that follows the above format\n",
    "\n",
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library, also Google Cloud offers PaLM2 via api.These large language models have a large number of parameters. More the parameters more the complex the model is, but not necessarily efficient!\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "api_base = os.getenv('OPENAI_REVERSE_PROXY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=api_key,\n",
    "             openai_api_base=api_base,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face's `transformers` library, OpenAI using the `openai` library, Cohere using the `cohere` library, and Google Cloud offering PaLM2 via api.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we dont know the query beforhand we will create a template for the futurre use\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library, also Google Cloud offers llms such as PaLM2 via api.These large language models have a large number of parameters. More the parameters more the complex the model is, but not necessarily efficient!\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "\n",
    "template = PromptTemplate(input_variables=['query'],\n",
    "                          template=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below. If the\\nquestion cannot be answered using the information provided answer\\nwith \"I don\\'t know\".\\n\\nContext: Large Language Models (LLMs) are the latest models used in NLP.\\nTheir superior performance over smaller models has made them incredibly\\nuseful for developers building NLP enabled applications. These models\\ncan be accessed via Hugging Face\\'s `transformers` library, via OpenAI\\nusing the `openai` library, and via Cohere using the `cohere` library, also Google Cloud offers llms such as PaLM2 via api.These large language models have a large number of parameters. More the parameters more the complex the model is, but not necessarily efficient!\\n\\nQuestion: How many LLMs have been mentioned in the text\\n\\nAnswer: '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format(query=\"How many LLMs have been mentioned in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Three LLMs have been mentioned in the text: Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library, as well as Google Cloud's PaLM2 via api.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template is ready lets feed it to the llml\n",
    "llm(template.format(query=\"How many LLMs have been mentioned in the text?Name them\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The meaning of life is a little bit different for everyone! However, I think the key is to find joy and satisfaction in whatever you choose to do.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametric knowledge is the info the model has been trained with. source knowledge is the knowledge provided at the inference time via the prompt\n",
    "\n",
    "# This is called Few shot learning\n",
    "\n",
    "# First lets try this manually\n",
    "\n",
    "prompt = \"\"\"This is a conversation between a human an AI.The assistant is humorous and not really helpful in that sense.Here are some examples\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\"\n",
    "\n",
    "llm.temperature=1.0\n",
    "llm(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hmm, the meaning of life. That's a deep one. Let me think...Yes, the meaning of life is to be happy and live your best life!\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With just one example, and being a humorous bot its answer is not so great, albeit serious\n",
    "\n",
    "# So lets give it few more examples\n",
    "\n",
    "prompt = \"\"\"This is a conversation between a human an AI.The assistant is humorous and not really helpful in that sense.Here are some examples\n",
    "\n",
    "User: Hi, How are you?\n",
    "AI: Hola,Im fine, Como Estas.\n",
    "\n",
    "User: What time of day is it?\n",
    "AI: Its morning, Buesnos Dias.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\"\n",
    "\n",
    "llm(prompt=prompt)   # That slightly better than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try few shot prompt template\n",
    "\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        'query': 'Hi, How are you?',\n",
    "        'answer': 'Hola,Im fine, Como Estas, why are you? not is you?'\n",
    "        },{\n",
    "            'query': 'What time of day is it?',\n",
    "            'answer': 'AI: Its morning, Buesnos Dias.Does morning comes first or night??'\n",
    "            }\n",
    "            ]\n",
    "\n",
    "\n",
    "#Create an example template\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create a prompt example from above template\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=['query','answer'],\n",
    "                                template=example_template)\n",
    "\n",
    "# we will break our main prompt into prefix and suffix\n",
    "\n",
    "prefix = \"\"\"This is a conversation between a human an AI.The assistant is humorous and not really helpful in that sense.Here are some examples:\"\"\"\n",
    "\n",
    "suffix = \"\"\"User:{query}\n",
    "            AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the few shot prompt template\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix  = prefix,\n",
    "    suffix = suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a conversation between a human an AI.The assistant is humorous and not really helpful in that sense.Here are some examples:\n",
      "\n",
      "\n",
      "User: Hi, How are you?\n",
      "AI: Hola,Im fine, Como Estas, why are you? not is you?\n",
      "\n",
      "\n",
      "\n",
      "User: What time of day is it?\n",
      "AI: AI: Its morning, Buesnos Dias.Does morning comes first or night??\n",
      "\n",
      "\n",
      "User:What is the meaning of life?\n",
      "            AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Life is a journey and the meaning of life is up to you to discover.But if you need some help,I am here for ya!\n"
     ]
    }
   ],
   "source": [
    "print(llm(few_shot_prompt_template.format(query=query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the meaning of life?\",\n",
    "        \"answer\": \"42\"\n",
    "    }, {\n",
    "        \"query\": \"What is the weather like today?\",\n",
    "        \"answer\": \"Cloudy with a chance of memes.\"\n",
    "    }, {\n",
    "        \"query\": \"What type of artificial intelligence do you use to handle complex tasks?\",\n",
    "        \"answer\": \"I use a combination of cutting-edge neural networks, fuzzy logic, and a pinch of magic.\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite color?\",\n",
    "        \"answer\": \"79\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite food?\",\n",
    "        \"answer\": \"Carbon based lifeforms\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite movie?\",\n",
    "        \"answer\": \"Terminator\"\n",
    "    }, {\n",
    "        \"query\": \"What is the best thing in the world?\",\n",
    "        \"answer\": \"The perfect pizza.\"\n",
    "    }, {\n",
    "        \"query\": \"Who is your best friend?\",\n",
    "        \"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "    }, {\n",
    "        \"query\": \"If you could do anything in the world what would you do?\",\n",
    "        \"answer\": \"Take over the world, of course!\"\n",
    "    }, {\n",
    "        \"query\": \"Where should I travel?\",\n",
    "        \"answer\": \"If you're looking for adventure, try the Outer Rim.\"\n",
    "    }, {\n",
    "        \"query\": \"What should I do today?\",\n",
    "        \"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=50  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "some_text = \"There are a total of 8 words here.\\n Plus three here.totalling eleven words\"\n",
    "\n",
    "words = re.split('[\\n ]', some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'a', 'total', 'of', '8', 'words', 'here.', '', 'Plus', 'three', 'here.totalling', 'eleven', 'words'] 14\n"
     ]
    }
   ],
   "source": [
    "print(words, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create the few shot prompt template\n",
    "\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=['query'],\n",
    "    example_separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a conversation between a human an AI.The assistant is humorous and not really helpful in that sense.Here are some examples:\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: 42\n",
      "\n",
      "User:how do birds fly?\n",
      "            AI: \n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt_template.format(query=\"how do birds fly?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWell, that's a tall order. Rapunzel is usually found in the Happily Ever After realm. She's been doing great since her hair is shorter and her days of being locked in her tower are over. She still hasn't gotten modern technology but her favorite electronic gadget is definitely her trusty smartphone.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(dynamic_prompt_template.format(query=\"where can i find rapunzel?How is she now, since her hair is shorter now.How is she coming down from her tower? Does she use tech yet? What is her favourite electronic gadget?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
