{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_base = os.getenv\n",
    "\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = requests.get(url='https://www.volza.com/p/soyabean/import/import-in-india/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(url.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "res = soup.find_all('span',attrs='ant-table-column-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i in res[:5]:\n",
    "    columns.append(''.join(i.text.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('tr'):\n",
    "    row_data = i.find_all('td')\n",
    "    row = [j.text for j in row_data[:5]]\n",
    "    length = len(data)\n",
    "    data.loc[length] = row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Saudi Aramco website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.aramco.com/en/news-media/news-archive'\n",
    "get = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('h3',attrs='search-results__result-title'):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.aramco.com/en/news-media/news-archive?query=&facets=content_item_type_s%3dNews&sort=pubdate%7cTrue&pubstart=&pubend=&page='\n",
    "def aramco_scraper(url:str,pages:int=68):\n",
    "     cont = []\n",
    "     for i in range(0,pages+1):\n",
    "         url2 = url + str(i)\n",
    "         response = requests.get(url2)\n",
    "         soup = BeautifulSoup(response.content, 'lxml')\n",
    "         results = soup.find_all('h3', attrs='search-results__result-title')\n",
    "         for i in results:\n",
    "              cont.append(i.text)\n",
    "     return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = aramco_scraper(url='https://www.aramco.com/en/news-media/news-archive?query=&facets=content_item_type_s%3dNews&sort=pubdate%7cTrue&pubstart=&pubend=&page=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aramco_news.txt','w+') as file:\n",
    "    for i in news:\n",
    "        file.write(i+'//\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aramco_scraper(url:str,pages:int=68):\n",
    "     cont = []\n",
    "     for i in range(0,pages+1):\n",
    "         url2 = url + str(i)\n",
    "         response = requests.get(url2)\n",
    "         soup = BeautifulSoup(response.content, 'lxml')\n",
    "         results = soup.find_all('p', attrs='search-results__result-description')\n",
    "         for i in results:\n",
    "              cont.append(i.text)\n",
    "     return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = aramco_scraper(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aramco_news_desc.txt', 'w+') as f:\n",
    "    for i in desc[1:]:\n",
    "        f.write(i+'//\\n\\n')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the news from the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import  BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "link = 'https://www.aramco.com/en/news-media/news-archive?query=&facets=content_item_type_s%3dNews&sort=pubdate%7cTrue&pubstart=&pubend=&page='\n",
    "\n",
    "get = requests.get(link)\n",
    "soup = BeautifulSoup(get.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "links = []\n",
    "for page in range(0,69):\n",
    "    url = link+str(page)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    for i in soup.find_all('div',attrs='search-results__result-wrapper'):\n",
    "        for j in i.find_all('a'):\n",
    "            #The links have facet which directs to the page displayed so we will have to \n",
    "            if 'facet' not in j.get('href'):\n",
    "                links.append('https://www.aramco.com'+j.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = []\n",
    "\n",
    "for i in links:\n",
    "    url = requests.get(str(i))\n",
    "    soup =  BeautifulSoup(url.text, 'html.parser')\n",
    "    for link in soup.find_all('div',attrs='text'):\n",
    "        para_ = []\n",
    "        for para in link.find_all('p'):\n",
    "            para_.append(para.text.strip(','))\n",
    "        para_ = ' '.join(para_)\n",
    "        full_text.append(para_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fulltext.txt\",\"w+\") as f:\n",
    "    f.writelines(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
